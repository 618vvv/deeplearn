{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  线性回归基于几个简单的假设：\n",
    "  首先，假设自变量和因变量之间的关系是线性的， 即可以表示为中元素的加权和，这里通常允许包含观测值的一些噪声； \n",
    "  其次，我们假设任何噪声都比较正常，如噪声遵循正态分布。 \"\"\"\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.在机器学习的术语中，该数据集称为训练数据集（training data set） 或训练集（training set）。\n",
    "2.每行数据（比如一次房屋交易相对应的数据）称为样本（sample）， 也可以称为数据点（data point）或数据样本（data instance）。 \n",
    "3.我们把试图预测的目标（比如预测房屋价格）称为标签（label）或目标（target）。\n",
    "4.预测所依据的自变量（面积和房龄）称为特征（feature）或协变量（covariate）。\n",
    "\n",
    "1.权重决定了每个特征对我们预测值的影响。\n",
    "2.偏置是指当所有特征都取值为0时，预测值应该为多少。\n",
    "3.仿射变换的特点是通过加权和对特征进行线性变换（linear transformation）， 并通过偏置项来进行平移（translation）。\n",
    "4. 输出的预测值由输入特征通过线性模型的仿射变换决定，仿射变换由所选权重和偏置确定。\n",
    " 5.给定一个数据集，我们的目标是寻找模型的权重和偏置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在开始寻找最好的模型参数（model parameters）和之前， 我们还需要两个东西：\n",
    " （1）一种模型质量的度量方式； \n",
    " （2）一种能够更新模型以提高模型预测质量的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.1.2. 损失函数\n",
    "损失函数（loss function）能够量化目标的实际值与预测值之间的差距。\n",
    "通常我们会选择非负数作为损失，且数值越小表示损失越小，完美预测时的损失为0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了度量模型在整个数据集上的质量，我们需计算在训练集个样本上的损失均值（也等价于求和）。\n",
    "在训练模型时，我们希望寻找一组参数（w*,b*）， 这组参数能最小化在所有训练样本上的总损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.1.3 解析解\n",
    "线性回归刚好是一个很简单的优化问题。 与我们将在本书中所讲到的其他大部分模型不同，线性回归的解可以用一个公式简单地表达出来， 这类解叫作解析解（analytical solution）。 首先，我们将偏置合并到参数中，合并方法是在包含所有参数的矩阵中附加一列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.1.4. 随机梯度下降\n",
    "本书中我们用到一种名为梯度下降（gradient descent）的方法， 这种方法几乎可以优化所有深度学习模型。 它通过不断地在损失函数递减的方向上更新参数来降低误差。\n",
    "我们通常会在每次需要计算更新的时候随机抽取一小批样本， 这种变体叫做小批量随机梯度下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表示每个小批量中的样本数，这也称为批量大小（batch size）。\n",
    "表示学习率（learning rate）。\n",
    "批量大小和学习率的值通常是手动预先指定，而不是通过模型训练得到的。\n",
    "这些可以调整但不在训练过程中更新的参数称为超参数（hyperparameter）。 \n",
    "调参（hyperparameter tuning）是选择超参数的过程。\n",
    "超参数通常是我们根据训练迭代结果来调整的， 而训练迭代结果是在独立的验证数据集（validation dataset）上评估得到的。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "算法会使得损失向最小值缓慢收敛，但却不能在有限的步数内非常精确地达到最小值。\n",
    "线性回归恰好是一个在整个域中只有一个最小值的学习问题。 \n",
    "但是对于像深度神经网络这样复杂的模型来说，损失平面上通常包含多个最小值。\n",
    " 深度学习实践者很少会去花费大力气寻找这样一组参数，使得在训练集上的损失达到最小。\n",
    "  事实上，更难做到的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失， 这一挑战被称为泛化（generalization）。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
